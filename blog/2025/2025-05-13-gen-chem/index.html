<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h2 id="introduction">Introduction</h2> <p>This experiment investigates advanced graph-to-sequence deep learning approaches for molecular design, focusing on generating chemically valid SMILES strings from molecular graphs. We compare:</p> <ul> <li> <strong>GNN→Transformer</strong>: A baseline message-passing GNN encoder with a Transformer decoder.</li> <li> <strong>Graphormer→Transformer</strong>: A structurally-biased Transformer encoder with explicit centrality, spatial, and edge encodings.</li> <li> <strong>Graphormer + Birdie→Transformer</strong>: The Graphormer model further trained with stochastic, corruption-based objectives (infilling, deshuffling, selective copying, standard copying) to improve robustness.</li> </ul> <p>All models are trained with a combined cross-entropy and REINFORCE‐style validity loss, rewarding chemically valid outputs via RDKit validation. citeturn0file0</p> <h2 id="background-and-motivation">Background and Motivation</h2> <p>Discovering novel drug‐like molecules traditionally requires expensive, manual exploration of vast chemical spaces. Language‐modeling techniques applied to SMILES can generate syntactically valid strings but often miss underlying graph topology, producing chemically invalid compounds. Bridging this gap demands encoder–decoder architectures that respect molecular graphs’ structure while leveraging powerful sequence modeling.</p> <h2 id="graph-based-generative-models">Graph-Based Generative Models</h2> <p><strong>Graph Neural Networks (GNNs)</strong> perform local message passing over nodes and edges, capturing atomic interactions but struggle with long-range dependencies and global structure (over‐smoothing). <strong>Graphormer</strong> extends Transformers to graphs by injecting:</p> <ol> <li> <strong>Centrality encodings</strong> (node degrees)</li> <li> <strong>Spatial encodings</strong> (shortest‐path distances)</li> <li> <strong>Edge encodings</strong> (bond‐type biases along paths)</li> <li> <strong>Virtual node</strong> (<code class="language-plaintext highlighter-rouge">[VNode]</code>) for global readout This combination enables rich, topology-aware representations.</li> </ol> <h2 id="problem-statement">Problem Statement</h2> <ul> <li> <strong>Representation mismatch</strong>: Linear SMILES fail to capture graph topology.</li> <li> <strong>Validity vs. fluency</strong>: Models optimized for token‐level accuracy often generate chemically invalid molecules.</li> <li> <strong>Robustness</strong>: Decoders can struggle with incomplete or noisy inputs, limiting diversity and generalization.</li> </ul> <h2 id="research-objectives">Research Objectives</h2> <ol> <li> <strong>Effective graph encoding</strong>: Compare standard GNN vs. Graphormer encoders.</li> <li> <strong>SMILES accuracy &amp; validity</strong>: Evaluate token-level accuracy and RDKit‐verified validity.</li> <li> <strong>Robustness via self-supervision</strong>: Apply Birdie training objectives to improve long-range dependency modeling.</li> <li> <strong>Comprehensive benchmarking</strong>: Quantitatively assess all variants on accuracy, validity, diversity, and noise resilience.</li> </ol> <h2 id="contributions">Contributions</h2> <ol> <li> <strong>Architectural comparison</strong> of three encoder–decoder variants (GNN, Graphormer, Graphormer+Birdie).</li> <li> <strong>Structural inductive biases</strong>: Integration of centrality, spatial, and edge encodings into attention.</li> <li> <strong>Validity‐aware loss</strong>: A REINFORCE‐style auxiliary loss rewarding chemically valid outputs.</li> <li> <strong>Birdie multi-task pretraining</strong>: Randomized infilling, deshuffling, selective copying, and autoencoding objectives.</li> <li> <strong>Full PyTorch pipeline</strong>: From SDF parsing and feature extraction to batched training and inference.</li> </ol> <h2 id="data-preparation">Data Preparation</h2> <p>We processed a dataset of ~100K molecules from <a href="https://www.ebi.ac.uk/chembl/" rel="external nofollow noopener" target="_blank">ChEMBL</a>, ensuring chemical diversity and drug-like properties:</p> <ul> <li> <strong>Molecule parsing</strong>: SDF files loaded via RDKit, extracting atom/bond features and canonical SMILES.</li> <li> <p><strong>Feature extraction</strong>:</p> <ul> <li> <strong>Node features</strong>: One-hot atom type, degree, formal charge, hybridization, aromaticity</li> <li> <strong>Edge features</strong>: One-hot bond type, conjugation, ring membership</li> </ul> </li> <li> <strong>Graph construction</strong>: Bi-directional adjacency with feature tensors for nodes and edges.</li> <li> <strong>Dataset splits</strong>: 80% train, 10% validation, 10% test; stratified by molecular weight distribution.</li> <li> <p><strong>Statistics</strong>:</p> <ul> <li> <strong>Avg. atoms per molecule</strong>: 23 ± 8</li> <li> <strong>SMILES length</strong>: 50 ± 15 tokens</li> </ul> </li> <li> <strong>Sequence tokenization</strong>: Character-level SMILES with special tokens <code class="language-plaintext highlighter-rouge">&lt;sos&gt;</code>, <code class="language-plaintext highlighter-rouge">&lt;eos&gt;</code>, <code class="language-plaintext highlighter-rouge">&lt;pad&gt;</code>.</li> <li> <p><strong>Padding &amp; batching</strong>:</p> <ul> <li>Node features padded to max 50 nodes per batch</li> <li>SMILES sequences padded to max length per batch</li> </ul> </li> <li> <strong>Data augmentation</strong> (Birdie only): Random masking/shuffling of graph chunks and SMILES segments during pretraining.</li> </ul> <blockquote> <p>Data processing from SDF → SMILES &amp; Tokenization</p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#parsing SMILES with RDKit
</span><span class="kn">from</span> <span class="n">rdkit</span> <span class="kn">import</span> <span class="n">Chem</span>
<span class="n">smiles</span> <span class="o">=</span> <span class="n">Chem</span><span class="p">.</span><span class="nc">MolToSmiles</span><span class="p">(</span><span class="n">molecule</span><span class="p">,</span> <span class="n">canonical</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># SMILES
</span><span class="n">SMILES</span><span class="p">:</span> <span class="sh">"</span><span class="s">CC(=O)O</span><span class="sh">"</span>
<span class="c1">#tokens 
</span><span class="n">Tokens</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">&lt;sos&gt;</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">C</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">C</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">(</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">O</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">)</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">O</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">&lt;eos&gt;</span><span class="sh">"</span><span class="p">]</span>

<span class="c1"># decoder input and labes (Simple pretraining)
</span><span class="n">dec_input_ids</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">&lt;sos&gt;</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">C</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">C</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">(</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">O</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">)</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">O</span><span class="sh">"</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">C</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">C</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">(</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">O</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">)</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">O</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">&lt;eos&gt;</span><span class="sh">"</span><span class="p">]</span>
</code></pre></div></div> <h2 id="model-architectures">Model Architectures</h2> <h3 id="gnn-encoder--transformer-decoder">GNN Encoder → Transformer Decoder</h3> <div class="fake-img l-page"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gnn-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gnn-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gnn-1400.webp"></source> <img src="/assets/img/gnn.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p><strong>Figure:</strong> GNN→Transformer architecture. Input molecular graph is embedded via an MPNN (3 layers, hidden=128), global readout pools to a 512-d vector, then passed to an 8-layer causal Transformer decoder (<code class="language-plaintext highlighter-rouge">d_model=512</code>, <code class="language-plaintext highlighter-rouge">heads=8</code>) for SMILES generation.</p> <h3 id="graphormer-encoder--transformer-decoder">Graphormer Encoder → Transformer Decoder</h3> <div class="fake-img l-page"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gf-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gf-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gf-1400.webp"></source> <img src="/assets/img/gf.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p><strong>Figure:</strong> Graphormer→Transformer. Graphormer encoder integrates centrality, spatial, and edge biases in self-attention across 6 layers (<code class="language-plaintext highlighter-rouge">d_model=512</code>). The pooled <code class="language-plaintext highlighter-rouge">[VNode]</code> token seeds the Transformer decoder similarly configured to the baseline.</p> <h3 id="graphormer--birdie--transformer-decoder">Graphormer + Birdie → Transformer Decoder</h3> <p>Birdie Graphormer→Transformer. Same as Graphormer, with stochastic Birdie objectives applied per batch to encoder inputs and SMILES targets (infilling, deshuffling, selective copying).</p> <h2 id="experiments--results">Experiments &amp; Results</h2> <ul> <li> <strong>Training</strong>: Batch size 16, 50 epochs, Adam lr=5e-6, early stopping (patience=5).</li> <li> <p><strong>Metrics</strong>:</p> <ul> <li> <strong>Final total loss</strong>: GNN=1.1, Graphormer=0.4, Graphormer+Birdie=0.3.</li> <li> <strong>Chemical validity</strong> (greedy decoding): 81.7%, 91.3%, <strong>92.0%</strong> respectively.</li> </ul> </li> </ul> <blockquote> <p><strong>Loss and validity comparisons</strong></p> </blockquote> <table> <thead> <tr> <th>Model</th> <th>Final Total Loss</th> <th>Chemical Validity (%)</th> </tr> </thead> <tbody> <tr> <td>GNN → Transformer</td> <td>1.10</td> <td>81.7</td> </tr> <tr> <td>Graphormer → Transformer</td> <td>0.40</td> <td>91.3</td> </tr> <tr> <td>Graphormer + Birdie → Transformer</td> <td>0.30</td> <td>92.0</td> </tr> </tbody> </table> <blockquote> <p><strong>Figure placeholder</strong>: Sample molecules from Graphormer+Birdie model</p> </blockquote> <div class="fake-img l-page"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/CHEMBL153534-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/CHEMBL153534-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/CHEMBL153534-1400.webp"></source> <img src="/assets/img/CHEMBL153534.png.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="fake-img l-page"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/CHEMBL440060-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/CHEMBL440060-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/CHEMBL440060-1400.webp"></source> <img src="/assets/img/CHEMBL440060.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p><strong>Findings</strong>:</p> <ul> <li>Graphormer’s structural biases drive large gains over GNNs.</li> <li>Birdie corruption objectives further boost robustness and validity.</li> <li>Ablations confirm spatial encoding and validity loss are most critical.</li> </ul> <h2 id="conclusion">Conclusion</h2> <p>Combining graph-aware self-attention with corruption-based pretraining substantially improves molecular SMILES generation. The Graphormer encoder captures global topology effectively, and Birdie objectives reinforce decoder robustness—achieving a 92% chemical validity rate and strong convergence behavior. citeturn0file0</p> <h2 id="future-work">Future Work</h2> <ul> <li> <strong>Multi-objective training</strong>: Incorporate property‐driven rewards (e.g., logP, drug-likeness).</li> <li> <strong>Scale-up</strong>: Pretrain on larger, diverse chemical libraries.</li> <li> <strong>Conditional generation</strong>: Guide molecule design toward target functionalities.</li> <li> <strong>Hybrid representations</strong>: Explore SELFIES or graph‐based decoders. citeturn0file0</li> </ul> <h2 id="citations">Citations</h2> <ol> <li>Basnet, S. (2025). <em>Generative Deep Learning Experiment in Molecule Generation</em> (Report).</li> <li>Ying, R. et al. (2021). <em>Do Transformers Really Perform Bad for Graph Representation?</em> (Graphormer).</li> <li>Hu, W. et al. (2020). <em>Strategies for Pre‐training Graph Neural Networks</em>.</li> <li>Vaswani, A. et al. (2017). <em>Attention Is All You Need</em>.</li> <li>Krenn, M. et al. (2020). <em>SELFIES: a robust molecular string representation</em>.</li> <li>Kipf, T. &amp; Welling, M. (2017). <em>Semi‐Supervised Classification with Graph Convolutional Networks</em>.</li> <li>RDKit: Open‐source cheminformatics; <a href="https://www.rdkit.org" rel="external nofollow noopener" target="_blank">https://www.rdkit.org</a> </li> </ol> </body></html>