<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Generative Deep Learning for Molecular SMILES Generation | Tsuyog Basnet</title> <meta name="author" content="Tsuyog Basnet"> <meta name="description" content="A comparative study of graph‐to‐sequence models using GNNs, Graphormer, and Birdie training for chemically valid molecule design."> <meta name="keywords" content="Machine-Learninng, Data-Scientist, researcher, NLP, personal-blog"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%A0&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://pvsnp9.github.io/blog/2025/gen-chem/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "Generative Deep Learning for Molecular SMILES Generation",
      "description": "A comparative study of graph‐to‐sequence models using GNNs, Graphormer, and Birdie training for chemically valid molecule design.",
      "published": "May 13, 2025",
      "authors": [
        {
          "author": "Vector Lab",
          "authorURL": "[https://www.linkedin.com/in/tsuyog/](https://www.linkedin.com/in/tsuyog/)",
          "affiliations": [
            {
              "name": "",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Tsuyog Basnet</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Experiments</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Generative Deep Learning for Molecular SMILES Generation</h1> <p>A comparative study of graph‐to‐sequence models using GNNs, Graphormer, and Birdie training for chemically valid molecule design.</p> </d-title><d-byline></d-byline><d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#introduction">Introduction</a></div> <div><a href="#background-and-motivation">Background and Motivation</a></div> <div><a href="#graph-based-generative-models">Graph-Based Generative Models</a></div> <div><a href="#problem-statement">Problem Statement</a></div> <div><a href="#research-objectives">Research Objectives</a></div> <div><a href="#contributions">Contributions</a></div> <div><a href="#data-preparation">Data Preparation</a></div> <div><a href="#model-architectures">Model Architectures</a></div> <ul> <li><a href="#gnn-encoder-transformer-decoder">GNN Encoder → Transformer Decoder</a></li> <li><a href="#graphormer-encoder-transformer-decoder">Graphormer Encoder → Transformer Decoder</a></li> <li><a href="#graphormer-birdie-transformer-decoder">Graphormer + Birdie → Transformer Decoder</a></li> </ul> <div><a href="#experiments-results">Experiments &amp; Results</a></div> <div><a href="#conclusion">Conclusion</a></div> <div><a href="#future-work">Future Work</a></div> <div><a href="#citations">Citations</a></div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>This experiment investigates advanced graph-to-sequence deep learning approaches for molecular design, focusing on generating chemically valid SMILES strings from molecular graphs. We compare:</p> <ol> <li> <strong>GNN→Transformer</strong>: A baseline message-passing GNN encoder with a Transformer decoder.</li> <li> <strong>Graphormer→Transformer</strong>: A structurally-biased Transformer encoder with explicit centrality, spatial, and edge encodings.</li> <li> <strong>Graphormer + Birdie→Transformer</strong>: The Graphormer model further trained with stochastic, corruption-based objectives (infilling, deshuffling, selective copying, standard copying) to improve robustness.</li> </ol> <p>All models are trained with a combined cross-entropy and REINFORCE‐style validity loss, rewarding chemically valid outputs via RDKit validation. citeturn0file0</p> <h2 id="background-and-motivation">Background and Motivation</h2> <p>Discovering novel drug‐like molecules traditionally requires expensive, manual exploration of vast chemical spaces. Language‐modeling techniques applied to SMILES can generate syntactically valid strings but often miss underlying graph topology, producing chemically invalid compounds. Bridging this gap demands encoder–decoder architectures that respect molecular graphs’ structure while leveraging powerful sequence modeling.</p> <h2 id="graph-based-generative-models">Graph-Based Generative Models</h2> <p><strong>Graph Neural Networks (GNNs)</strong> perform local message passing over nodes and edges, capturing atomic interactions but struggle with long-range dependencies and global structure (over‐smoothing). <strong>Graphormer</strong> extends Transformers to graphs by injecting:</p> <ol> <li> <strong>Centrality encodings</strong> (node degrees)</li> <li> <strong>Spatial encodings</strong> (shortest‐path distances)</li> <li> <strong>Edge encodings</strong> (bond‐type biases along paths)</li> <li> <strong>Virtual node</strong> (<code class="language-plaintext highlighter-rouge">[VNode]</code>) for global readout This combination enables rich, topology-aware representations.</li> </ol> <h2 id="problem-statement">Problem Statement</h2> <ul> <li> <strong>Representation mismatch</strong>: Linear SMILES fail to capture graph topology.</li> <li> <strong>Validity vs. fluency</strong>: Models optimized for token‐level accuracy often generate chemically invalid molecules.</li> <li> <strong>Robustness</strong>: Decoders can struggle with incomplete or noisy inputs, limiting diversity and generalization.</li> </ul> <h2 id="research-objectives">Research Objectives</h2> <ol> <li> <strong>Effective graph encoding</strong>: Compare standard GNN vs. Graphormer encoders.</li> <li> <strong>SMILES accuracy &amp; validity</strong>: Evaluate token-level accuracy and RDKit‐verified validity.</li> <li> <strong>Robustness via self-supervision</strong>: Apply Birdie training objectives to improve long-range dependency modeling.</li> <li> <strong>Comprehensive benchmarking</strong>: Quantitatively assess all variants on accuracy, validity, diversity, and noise resilience.</li> </ol> <h2 id="contributions">Contributions</h2> <ol> <li> <strong>Architectural comparison</strong> of three encoder–decoder variants (GNN, Graphormer, Graphormer+Birdie).</li> <li> <strong>Structural inductive biases</strong>: Integration of centrality, spatial, and edge encodings into attention.</li> <li> <strong>Validity‐aware loss</strong>: A REINFORCE‐style auxiliary loss rewarding chemically valid outputs.</li> <li> <strong>Birdie multi-task pretraining</strong>: Randomized infilling, deshuffling, selective copying, and autoencoding objectives.</li> <li> <strong>Full PyTorch pipeline</strong>: From SDF parsing and feature extraction to batched training and inference.</li> </ol> <hr> <h2 id="data-preparation">Data Preparation</h2> <p>We processed a dataset of ~100K molecules from <a href="https://www.ebi.ac.uk/chembl/" rel="external nofollow noopener" target="_blank">ChEMBL</a>, ensuring chemical diversity and drug-like properties:</p> <ul> <li> <strong>Molecule parsing</strong>: SDF files loaded via RDKit, extracting atom/bond features and canonical SMILES.</li> <li> <p><strong>Feature extraction</strong>:</p> <ul> <li> <strong>Node features</strong>: One-hot atom type, degree, formal charge, hybridization, aromaticity</li> <li> <strong>Edge features</strong>: One-hot bond type, conjugation, ring membership</li> </ul> </li> <li> <strong>Graph construction</strong>: Bi-directional adjacency with feature tensors for nodes and edges.</li> <li> <strong>Dataset splits</strong>: 80% train, 10% validation, 10% test; stratified by molecular weight distribution.</li> <li> <p><strong>Statistics</strong>:</p> <ul> <li> <strong>Avg. atoms per molecule</strong>: 23 ± 8</li> <li> <strong>SMILES length</strong>: 50 ± 15 tokens</li> </ul> </li> <li> <strong>Sequence tokenization</strong>: Character-level SMILES with special tokens <code class="language-plaintext highlighter-rouge">&lt;sos&gt;</code>, <code class="language-plaintext highlighter-rouge">&lt;eos&gt;</code>, <code class="language-plaintext highlighter-rouge">&lt;pad&gt;</code>.</li> <li> <p><strong>Padding &amp; batching</strong>:</p> <ul> <li>Node features padded to max 50 nodes per batch</li> <li>SMILES sequences padded to max length per batch</li> </ul> </li> <li> <strong>Data augmentation</strong> (Birdie only): Random masking/shuffling of graph chunks and SMILES segments during pretraining.</li> </ul> <blockquote> <p>Data processing from SDF → SMILES &amp; Tokenization</p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#parsing SMILES with RDKit
</span><span class="kn">from</span> <span class="n">rdkit</span> <span class="kn">import</span> <span class="n">Chem</span>
<span class="n">smiles</span> <span class="o">=</span> <span class="n">Chem</span><span class="p">.</span><span class="nc">MolToSmiles</span><span class="p">(</span><span class="n">molecule</span><span class="p">,</span> <span class="n">canonical</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># SMILES
</span><span class="n">SMILES</span><span class="p">:</span> <span class="sh">"</span><span class="s">CC(=O)O</span><span class="sh">"</span>
<span class="c1">#tokens 
</span><span class="n">Tokens</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">&lt;sos&gt;</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">C</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">C</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">(</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">O</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">)</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">O</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">&lt;eos&gt;</span><span class="sh">"</span><span class="p">]</span>

<span class="c1"># decoder input and labes (Simple pretraining)
</span><span class="n">dec_input_ids</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">&lt;sos&gt;</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">C</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">C</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">(</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">O</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">)</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">O</span><span class="sh">"</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">C</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">C</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">(</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">O</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">)</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">O</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">&lt;eos&gt;</span><span class="sh">"</span><span class="p">]</span>
</code></pre></div></div> <hr> <h2 id="model-architectures">Model Architectures</h2> <h3 id="gnn-encoder--transformer-decoder">GNN Encoder → Transformer Decoder</h3> <div class="fake-img l-page"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gnn-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gnn-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gnn-1400.webp"></source> <img src="/assets/img/gnn.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p><strong>Figure:</strong> GNN→Transformer architecture. Input molecular graph is embedded via an MPNN (3 layers, hidden=128), global readout pools to a 512-d vector, then passed to an 8-layer causal Transformer decoder (<code class="language-plaintext highlighter-rouge">d_model=512</code>, <code class="language-plaintext highlighter-rouge">heads=8</code>) for SMILES generation.</p> <h3 id="graphormer-encoder--transformer-decoder">Graphormer Encoder → Transformer Decoder</h3> <div class="fake-img l-page"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gf-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gf-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gf-1400.webp"></source> <img src="/assets/img/gf.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p><strong>Figure:</strong> Graphormer→Transformer. Graphormer encoder integrates centrality, spatial, and edge biases in self-attention across 6 layers (<code class="language-plaintext highlighter-rouge">d_model=512</code>). The pooled <code class="language-plaintext highlighter-rouge">[VNode]</code> token seeds the Transformer decoder similarly configured to the baseline.</p> <h3 id="graphormer--birdie--transformer-decoder">Graphormer + Birdie → Transformer Decoder</h3> <p>Birdie Graphormer→Transformer. Same as Graphormer, with stochastic Birdie objectives applied per batch to encoder inputs and SMILES targets (infilling, deshuffling, selective copying).</p> <h2 id="experiments--results">Experiments &amp; Results</h2> <ul> <li> <strong>Training</strong>: Batch size 16, 50 epochs, Adam lr=5e-6, early stopping (patience=5).</li> <li> <p><strong>Metrics</strong>:</p> <ul> <li> <strong>Final total loss</strong>: GNN=1.1, Graphormer=0.4, Graphormer+Birdie=0.3.</li> <li> <strong>Chemical validity</strong> (greedy decoding): 81.7%, 91.3%, <strong>92.0%</strong> respectively.</li> </ul> </li> </ul> <blockquote> <p><strong>Loss and validity comparisons</strong></p> </blockquote> <table> <thead> <tr> <th>Model</th> <th>Final Total Loss</th> <th>Chemical Validity (%)</th> </tr> </thead> <tbody> <tr> <td>GNN → Transformer</td> <td>1.10</td> <td>81.7</td> </tr> <tr> <td>Graphormer → Transformer</td> <td>0.40</td> <td>91.3</td> </tr> <tr> <td>Graphormer + Birdie → Transformer</td> <td>0.30</td> <td>92.0</td> </tr> </tbody> </table> <blockquote> <p><strong>Figure placeholder</strong>: Sample molecules from Graphormer+Birdie model</p> </blockquote> <div class="row justify-content-sm-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/CHEMBL153534-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/CHEMBL153534-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/CHEMBL153534-1400.webp"></source> <img src="/assets/img/CHEMBL153534.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="row justify-content-sm-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/CHEMBL440060-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/CHEMBL440060-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/CHEMBL440060-1400.webp"></source> <img src="/assets/img/CHEMBL440060.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <hr> <p><strong>Findings</strong>:</p> <ul> <li>Graphormer’s structural biases drive large gains over GNNs.</li> <li>Birdie corruption objectives further boost robustness and validity.</li> <li>Ablations confirm spatial encoding and validity loss are most critical.</li> </ul> <hr> <h2 id="conclusion">Conclusion</h2> <p>Combining graph-aware self-attention with corruption-based pretraining substantially improves molecular SMILES generation. The Graphormer encoder captures global topology effectively, and Birdie objectives reinforce decoder robustness—achieving a 92% chemical validity rate and strong convergence behavior. citeturn0file0</p> <h2 id="future-work">Future Work</h2> <ul> <li> <strong>Multi-objective training</strong>: Incorporate property‐driven rewards (e.g., logP, drug-likeness).</li> <li> <strong>Scale-up</strong>: Pretrain on larger, diverse chemical libraries.</li> <li> <strong>Conditional generation</strong>: Guide molecule design toward target functionalities.</li> <li> <strong>Hybrid representations</strong>: Explore SELFIES or graph‐based decoders. citeturn0file0</li> </ul> <hr> <h2 id="citations">Citations</h2> <ol> <li>Basnet, S. (2025). <em>Generative Deep Learning Experiment in Molecule Generation</em> (Report).</li> <li>Ying, R. et al. (2021). <em>Do Transformers Really Perform Bad for Graph Representation?</em> (Graphormer).</li> <li>Hu, W. et al. (2020). <em>Strategies for Pre‐training Graph Neural Networks</em>.</li> <li>Vaswani, A. et al. (2017). <em>Attention Is All You Need</em>.</li> <li>Krenn, M. et al. (2020). <em>SELFIES: a robust molecular string representation</em>.</li> <li>Kipf, T. &amp; Welling, M. (2017). <em>Semi‐Supervised Classification with Graph Convolutional Networks</em>.</li> <li>RDKit: Open‐source cheminformatics; <a href="https://www.rdkit.org" rel="external nofollow noopener" target="_blank">https://www.rdkit.org</a> </li> </ol> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Tsuyog Basnet. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: May 13, 2025. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>